{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7bbff5403b40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#sampling from a std normal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#<class 'tensorflow.python.framework.ops.Tensor'>\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "a=tf.random_normal([2,3],0.0,1.0,dtype=tf.float32)  #sampling from a std normal\n",
    "print(type(a))\n",
    "#<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "tf.InteractiveSession()  # run an interactive session in Tf.\n",
    "    \n",
    "a_np=a.eval()\n",
    "print(type(a_np))\n",
    "#<class 'numpy.ndarray'>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySwarms\n",
    "import pyswarms as ps\n",
    "\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Convolutional Neural Network\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "visible = Input(shape=(64,64,1))\n",
    "conv1 = Conv2D(32, kernel_size=4, activation='relu')(visible)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(16, kernel_size=4, activation='relu')(pool1)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, kernel_size=4, activation='relu')(pool2)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "#conv4 = Conv2D(16, kernel_size=4, activation='relu')(pool3)\n",
    "#pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "flat = Flatten()(pool3)\n",
    "\n",
    "#hidden1 = Dense(10, activation='relu')(flat)\n",
    "#output = Dense(1, activation='sigmoid')(hidden1)\n",
    "#model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "#print(model.summary())\n",
    "\n",
    "\n",
    "\n",
    "# np_array = flat\n",
    "# numpy-arrays-to-tensorflow-tensors-and-back.py file\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#<class 'tensorflow.python.framework.ops.Tensor'>\n",
    "tf.InteractiveSession()  # run an interactive session in Tf.\n",
    " \n",
    "flat_np= tf.stack([flat])\n",
    "X=flat_np\n",
    "#flat_np = flat.eval()\n",
    "print(type(flat_np))\n",
    "#<class 'numpy.ndarray'>   \n",
    "\n",
    "#tf.stack([x, y, z])\n",
    "# numpy-arrays-to-tensorflow-tensors-and-back.py file\n",
    "# ...\n",
    "# sess = tf.Session()\n",
    "\n",
    "# numpy-arrays-to-tensorflow-tensors-and-back.py file\n",
    "# ...\n",
    "#with sess.as_default():\n",
    " \n",
    "    #tensor = tf.constant(np_array)\n",
    "    \n",
    "# numpy-arrays-to-tensorflow-tensors-and-back.py file\n",
    "# ...\n",
    "    # print(tensor)\n",
    "\n",
    "# command line\n",
    "#python numpy-arrays-to-tensorflow-tensors-and-back.py\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#X = tf.make_ndarray(flat.op.get_attr('value'))\n",
    "#tf.reset_default_graph()\n",
    "#print(flat.name)\n",
    "\n",
    "#sess = tf.Session()\n",
    "#with sess.as_default():  X = flat.eval()   # the input to the backpropagation optimized by pso\n",
    "\n",
    "#X = tf.constant([1,2,3]).eval()\n",
    "#print((X.shape, \"X= \"))\n",
    "#print(type(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def dot(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "\n",
    "# Forward propagation\n",
    "def forward_prop(params):\n",
    "    \"\"\"Forward propagation as objective function\n",
    "\n",
    "    This computes for the forward propagation of the neural network, as\n",
    "    well as the loss. It receives a set of parameters that must be\n",
    "    rolled-back into the corresponding weights and biases.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    params: np.ndarray\n",
    "        The dimensions should include an unrolled version of the\n",
    "        weights and biases.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The computed negative log-likelihood loss given the parameters\n",
    "    \"\"\"\n",
    "    # Neural network architecture\n",
    "    n_inputs = 800\n",
    "    n_hidden = 1000\n",
    "    #n_hidden_2 = 1000\n",
    "    n_classes = 10\n",
    "\n",
    "    # Roll-back the weights and biases\n",
    "    W1 = params[0:800000].reshape((n_inputs,n_hidden))\n",
    "    b1 = params[800000:801000].reshape((n_hidden,))\n",
    "    W2 = params[801000:811000].reshape((n_hidden,n_classes,))\n",
    "    b2 = params[811000:811010].reshape((n_classes,))\n",
    "\n",
    "    # Perform forward propagation\n",
    "    z1 = add(dot(X,W1),b1)  # Pre-activation in Layer 1\n",
    "    a1 = np.tanh(z1)     # Activation in Layer 1\n",
    "    z2 = add(dot(a1,W2),b2)  # Pre-activation in Layer 2\n",
    "    logits = z2          # Logits for Layer 2\n",
    "\n",
    "    # Compute for the softmax of the logits\n",
    "    exp_scores = np.exp(logits)    # np.exp means exponential function\n",
    "    probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)   #axis=1 means columns\n",
    "\n",
    "    # Compute for the negative log likelihood\n",
    "    N = 150 # Number of samples\n",
    "    corect_logprobs = -np.log(probs[range(N), y])\n",
    "    loss = np.sum(corect_logprobs) / N\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X):\n",
    "    \"\"\"Higher-level method to do forward_prop in the\n",
    "    whole swarm.\n",
    "\n",
    "    Inputs\n",
    "    ------\n",
    "    x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "        The swarm that will perform the search\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray of shape (n_particles, )\n",
    "        The computed loss for each particle\n",
    "    \"\"\"\n",
    "    n_particles = X.shape[0]\n",
    "    j = [forward_prop(X[i]) for i in range(n_particles)]\n",
    "    return np.array(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Initialize swarm\n",
    "options = {'c1': 0.5, 'c2': 0.3, 'w':0.9}\n",
    "\n",
    "# Call instance of PSO\n",
    "dimensions = ( 800 * 1000) + (1000 * 10) + 1000 + 10\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=2, dimensions=dimensions, options=options)\n",
    "\n",
    "# Perform optimization\n",
    "cost, pos = optimizer.optimize(f, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
